{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "\n",
    "def run_dino(dino, image, text_prompt='food', box_threshold=0.4, text_threshold=0.1):\n",
    "    boxes, logits, phrases = predict(\n",
    "        model = dino, \n",
    "        image = image, \n",
    "        caption = text_prompt, \n",
    "        box_threshold = box_threshold, \n",
    "        text_threshold = text_threshold\n",
    "    )\n",
    "    return boxes, logits, phrases\n",
    "\n",
    "model = load_model('GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py', 'groundingdino_swint_ogc.pth')\n",
    "\n",
    "os.system('wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg')\n",
    "image_source, image = load_image('dog.jpeg')\n",
    "boxes, logits, phrases = run_dino(dino, image, text_prompt='dog')\n",
    "\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "sv.plot_image(annotated_frame, (8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated the dataset using Grounding DINO following the directory format for fine-tuning YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def annotate(dino, data, data_size, data_dir):\n",
    "    data = data.train_test_split(train_size=min(len(data), data_size))['train']\n",
    "\n",
    "    image_dir = f'{data_dir}/images'\n",
    "    label_dir = f'{data_dir}/labels'\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "        image_path = f'{image_dir}/{i:06d}.png'\n",
    "        label_path = f'{label_dir}/{i:06d}.txt'\n",
    "        image = d['image'].resize((640, 640))\n",
    "        image.save(image_path)\n",
    "        \n",
    "        image_source, image = load_image(image_path)\n",
    "        boxes, logits, phrases = run_dino(dino, image)\n",
    "\n",
    "        label = ['0 ' + ' '.join(list(map(str, b))) for b in boxes.tolist()]\n",
    "        label = '\\n'.join(label)\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(label)\n",
    "\n",
    "\n",
    "data = load_dataset('food101')\n",
    "annotate(dino, data['train'], 3000, 'data/train')\n",
    "annotate(dino, data['validation'], 1000, 'data/valid')\n",
    "\n",
    "config = {\n",
    "    'names': ['food'],\n",
    "    'nc': 1,\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images'\n",
    "}\n",
    "\n",
    "with open('data/data.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning YOLOv8 using Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolo = YOLO('yolov8n.pt')\n",
    "yolo.train(data='/content/data/data.yaml', epochs=5)\n",
    "valid_results = yolo.val()\n",
    "print(valid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_yolo(yolo, image_url, conf=0.25, iou=0.7):\n",
    "    results = yolo(image_url, conf=conf, iou=iou)\n",
    "    res = results[0].plot()[:, :, [2,1,0]]\n",
    "    return Image.fromarray(res)\n",
    "    \n",
    "yolo = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "image_url = 'test-01.jpg'\n",
    "predict(image_url)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
